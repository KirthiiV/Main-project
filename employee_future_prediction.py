# -*- coding: utf-8 -*-
"""Employee Future prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IFGujWbFbXFxqIj1RUZJ4JJPOnHndZNJ
"""

#Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report, auc, roc_curve, precision_recall_curve
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.metrics import accuracy_score

#Dataset importion
df = pd.read_csv('/content/Employee.csv')
df.head()

#Dataset information
df.info()

#Checking null values
df.isna().sum()

#Checking columns
df.columns

#Checking value counts
df['Education'].value_counts()

df['Education'].unique()

#EDA
#Countplot
sns.countplot(x=df['Education'])
plt.title("Education Distributions")
plt.xlabel("Education",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

#Ordinal Encoder
oe = OrdinalEncoder(categories=[['Bachelors', 'Masters', 'PHD']])

df['Education'] = oe.fit_transform(df[['Education']])

df['Education'].value_counts()

df['City'].value_counts()

df['City'].value_counts().plot(kind='pie', autopct="%.1f%%")
plt.legend()
plt.show()

sns.countplot(x=df['City'])
plt.title("City Distributions")
plt.xlabel("City",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

df['City'].unique()

city = pd.get_dummies(df['City'],prefix="City",dtype="int")
city.head()

df['Gender'].value_counts()

df['Gender'].unique()

sns.countplot(x=df['Gender'])
plt.title("Gender Distributions")
plt.xlabel("Gender",fontsize=12)
plt.ylabel("Number of Count")
plt.show()

df['Gender'].value_counts().plot(kind='pie',autopct="%.1f%%")
plt.legend()
plt.show()

#One hot encoding
gender = pd.get_dummies(df['Gender'],prefix='Gender',dtype='int')
gender

df['PaymentTier'].value_counts()

df['PaymentTier'].value_counts().plot(kind='pie',autopct="%.1f%%")
plt.legend()
plt.show()

sns.countplot(x=df['PaymentTier'])
plt.title("PaymentTier Distributions")
plt.xlabel("PaymentTier",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

df['Age'].unique()

sns.kdeplot(df['Age'])
plt.title("KdePlot Age",fontsize=14)
plt.xlabel("Age",fontsize=12)
plt.ylabel("Number of Counts",fontsize=12)
plt.show()

df['EverBenched'].value_counts()

df['EverBenched'].value_counts().plot(kind="pie",autopct='%.1f%%')
plt.legend()
plt.show()

sns.countplot(x=df['EverBenched'])
plt.title("EverBenched Distributions")
plt.xlabel("EverBenched",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

#One hot encoding
everbenched = pd.get_dummies(df['EverBenched'],prefix='EverBenched',dtype='int')
everbenched

df['ExperienceInCurrentDomain'].unique()

df['ExperienceInCurrentDomain'].value_counts()

sns.countplot(x=df['ExperienceInCurrentDomain'])
plt.title("ExperienceInCurrentDomain Distributions")
plt.xlabel("ExperienceInCurrentDomain",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

df['LeaveOrNot'].value_counts()

df['LeaveOrNot'].value_counts().plot(kind='pie',autopct="%.1f%%")
plt.legend()
plt.show()

sns.countplot(x=df['LeaveOrNot'])
plt.title("LeaveOrNot Distributions")
plt.xlabel("LeaveOrNot",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

df['JoiningYear'].unique()

sns.countplot(x=df['JoiningYear'])
plt.title("JoiningYear Distributions")
plt.xlabel("JoiningYear",fontsize=12)
plt.ylabel("Number of Count",fontsize=12)
plt.show()

df['JoiningYear'].value_counts().plot(kind='pie',autopct="%.1f%%")
plt.legend()
plt.show()

df1 = pd.concat([df,city,gender,everbenched],axis=1)
df1

df1 = df1.drop(['City','Gender','EverBenched'],axis=1)
df1

#Split the data
x = df1.drop('LeaveOrNot',axis=1)
y = df1['LeaveOrNot']

x

y

x_train,x_test,y_train,y_test = train_test_split(x,y,shuffle=True,test_size=0.10)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

#Kdeplot
plt.figure(figsize=(15,25))
i=1
for col in x.columns:
    plt.subplot(5,3,i)
    sns.kdeplot(x[col])
    i+=1

#Outlier detection
plt.figure(figsize=(15,25))
i=1
for col in x.columns:
    plt.subplot(5,3,i)
    x[[col]].boxplot()
    i+=1

#Heatmap
plt.figure(figsize=(10,5))
sns.heatmap(df.drop(['Education', 'City', 'Gender', 'EverBenched'], axis=1).iloc[:,:-1].corr(), annot=True, cmap="coolwarm")

#Skewness
x.skew()

#data scaling
scaler = MinMaxScaler()
scaler.fit(x_train)

x_train_scaled = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)
x_test_scaled = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)

x_train_scaled

# Models
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors
from sklearn.ensemble import RandomForestClassifier

# Evaluation metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, ConfusionMatrixDisplay

# Ignore os warnings
from warnings import filterwarnings
filterwarnings('ignore')

#Model building
acc_data_tr = []
acc_data_ts = []
for i in range(1,15):
    knn_model = KNeighborsClassifier(n_neighbors=i)
    knn_model.fit(x_train_scaled,y_train)
    acc_tr = knn_model.score(x_train_scaled,y_train)
    acc_ts = knn_model.score(x_test_scaled,y_test)
    acc_data_tr.append(acc_tr)
    acc_data_ts.append(acc_ts)

acc_data_tr

acc_data_ts

plt.plot(range(1,15),acc_data_tr,  linewidth=1, markersize=5,label='Training Accuracy')
plt.plot(range(1,15),acc_data_ts,  linewidth=1, markersize=5,label='Testing Accuracy')
plt.title("Accuracy vs Number of Neighbors",fontsize=12)
plt.xlabel("Number of Neighbors k", fontsize=12)
plt.ylabel("Accuracy",fontsize=12)
plt.legend()
plt.show()

#KNeighbour classifier
# Take k=4
knn = KNeighborsClassifier(n_neighbors=4)
knn.fit(x_train_scaled,y_train)

#Model evaulation on train and test
y_pred = knn.predict(x_test_scaled)
y_pred_tr = knn.predict(x_train_scaled)

print("Accuracy on Test Data:",accuracy_score(y_test,y_pred))
print("Accuracy on Train Data:",accuracy_score(y_train,y_pred_tr))

print("---Model Performance on Test Data---")
print()
print("Confusion Matrix:\n",confusion_matrix(y_test,y_pred))
print()
print("Classification Report:\n",classification_report(y_test,y_pred))

y_pred[:15]

y_test.values[:15]

#ROC curve
y_prob = knn.predict_proba(x_test_scaled)

fpr,tpr,threshold = roc_curve(y_test,y_prob[:,1])
print("ROC-AUC:",auc(fpr,tpr))

plt.plot(fpr,tpr,linestyle='--',color='green', label='KNN')
plt.title("ROC - AUC Curve",fontsize=14)
plt.xlabel("FPR",fontsize=12)
plt.ylabel("TPR",fontsize=12)
plt.legend()
plt.show()

#PR curve
p,r,t = precision_recall_curve(y_test,y_prob[:,1])
print("PR - AUC :",auc(r,p))

plt.plot(r, p ,linestyle='--',color='orange', label='KNN')
plt.title("Precision Recall - AUC Curve",fontsize=14)
plt.xlabel("Recall",fontsize=12)
plt.ylabel("Precision",fontsize=12)
plt.legend()
plt.show()

#MLP classifier
mlp = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', solver='adam', max_iter=250, random_state=0)

# Train
model = mlp.fit(x_train, y_train)

acc_train = accuracy_score(model.predict(x_train), y_train)
print(f'Accuracy for training: {acc_train*100:.2f}%')

# Test
pred = model.predict(x_test)

acc = accuracy_score(y_test, pred)
prec = precision_score(y_test, pred)

print()
print(f'Accuracy: {acc*100:.2f}%')
print(f'Precision: {prec*100:.2f}%')

cm = confusion_matrix(y_test, pred)
cmd = ConfusionMatrixDisplay(cm)
cmd.plot()

#Random Forest classifier
rf = RandomForestClassifier()

# Train
model = rf.fit(x_train, y_train)

acc_train = accuracy_score(model.predict(x_train), y_train)
print(f'Accuracy for training: {acc_train*100:.2f}%')

# Test
pred = model.predict(x_test)

acc = accuracy_score(y_test, pred)
prec = precision_score(y_test, pred)

print()
print(f'Acuracy: {acc*100:.2f}%')
print(f'Precision: {prec*100:.2f}%')

cm = confusion_matrix(y_test, pred)
cmd = ConfusionMatrixDisplay(cm)
cmd.plot()